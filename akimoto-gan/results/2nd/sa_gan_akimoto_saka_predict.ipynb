{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sa_gan-akimoto_saka_predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dY8BtSTNO79h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b148b18-2e21-4c08-bd9d-216893fb0854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "34IOGKkSAeos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.utils as vutils"
      ],
      "metadata": {
        "id": "HRyjDn9-z36p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64)\n",
        "parser.add_argument(\"--nch_g\", type=int, default=64)\n",
        "parser.add_argument(\"--nch_d\", type=int, default=64)\n",
        "parser.add_argument(\"--z_dim\", type=int, default=100) # noize dimension\n",
        "opt = parser.parse_args(args=[])"
      ],
      "metadata": {
        "id": "OaM2EWy8bNa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        out_channels = in_channels // 8\n",
        "        self.fx_1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.gx_1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.hx_1x1 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        self.softmax = nn.Softmax(dim=-2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.size()\n",
        "        fx = self.fx_1x1(x).view(B, -1, H * W).permute(0, 2, 1) # 転置\n",
        "        gx = self.gx_1x1(x).view(B, -1, H * W)\n",
        "        hx = self.hx_1x1(x).view(B, -1, H * W)\n",
        "        s_mtx = torch.bmm(fx, gx)   # ミニバッチ毎に行列積を計算\n",
        "        attention = self.softmax(s_mtx)\n",
        "        o = torch.bmm(hx, attention)    # attention で重み付けられた入力が返ってくる\n",
        "        o = o.view(B, -1, H, W)\n",
        "        out = x + self.gamma * o\n",
        "        return out"
      ],
      "metadata": {
        "id": "fFMDt8LzzuyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, self_attention, z_dim=100, ngf=64, nc=3):   # nc=1 for black-and-white images\n",
        "        super().__init__()\n",
        "        self.convt1 = self.conv_trans_layers(z_dim, 8*ngf, 4, 1, 0, True)\n",
        "        self.convt2 = self.conv_trans_layers(8*ngf, 4*ngf, 4, 2, 1, True)\n",
        "        self.convt3 = self.conv_trans_layers(4*ngf, 2*ngf, 4, 2, 1, True)\n",
        "        self.attention1 = self_attention(2 * ngf)\n",
        "        self.convt4 = self.conv_trans_layers(2*ngf, ngf, 4, 2, 1, True)\n",
        "        self.attention2 = self_attention(ngf)\n",
        "        self.convt5 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def conv_trans_layers(in_channels, out_channels, kernel_size, stride, padding, has_norm):\n",
        "        layers = [nn.utils.spectral_norm(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding))]\n",
        "        if has_norm:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        net = nn.Sequential(*layers)\n",
        "        return net\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.convt1(x)\n",
        "        out = self.convt2(out)\n",
        "        out = self.convt3(out)\n",
        "        out = self.attention1(out)\n",
        "        out = self.convt4(out)\n",
        "        out = self.attention2(out)\n",
        "        out = self.convt5(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "GZ2KZwqaz5kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/akimoto/gan_saka\"\n",
        "\n",
        "model_name = \"SAGAN\"\n",
        "f_path_result = f\"{BASE_DIR}/result/{model_name}\"\n",
        "f_path_params = f\"{BASE_DIR}/params/{model_name}\"\n",
        "\n",
        "os.makedirs(f_path_result, exist_ok=True)\n",
        "os.makedirs(f_path_params, exist_ok=True)"
      ],
      "metadata": {
        "id": "XVweVhx11gnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Generator(SelfAttention, z_dim=opt.z_dim, ngf=opt.nch_g)\n",
        "model.load_state_dict(torch.load(f\"{BASE_DIR}/params/{model_name}/g_0499.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyEEZq4o5AYv",
        "outputId": "ae336e83-17f2-40a8-af2a-3bfa55033bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (convt1): Sequential(\n",
              "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (convt2): Sequential(\n",
              "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (convt3): Sequential(\n",
              "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (attention1): SelfAttention(\n",
              "    (fx_1x1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (gx_1x1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (hx_1x1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (softmax): Softmax(dim=-2)\n",
              "  )\n",
              "  (convt4): Sequential(\n",
              "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (attention2): SelfAttention(\n",
              "    (fx_1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (gx_1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (hx_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (softmax): Softmax(dim=-2)\n",
              "  )\n",
              "  (convt5): Sequential(\n",
              "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.to(device)\n",
        "# noise = torch.randn(batch_size, opt.z_dim, 1, 1).to(device)\n",
        "noise = torch.randn(64, opt.z_dim, 1, 1)\n",
        "fake_imgs = model(noise)\n",
        "\n",
        "\n",
        "# save imgs and params\n",
        "for i in range(64):\n",
        "    \n",
        "    # show and save fake imgs\n",
        "    grid_imgs = vutils.make_grid(fake_imgs[:25].detach() + 0.5, nrow=5)\n",
        "    # print(fake_imgs[i])\n",
        "    img = fake_imgs[i].detach().numpy()\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    # plt.show()\n",
        "    plt.axis('off')\n",
        "    plt.savefig(fname=f\"{BASE_DIR}/imgs_show/{i}.png\", transparent = True, bbox_inches = 'tight', pad_inches = 0)\n",
        "\n",
        "    # save\n",
        "    img = (fake_imgs[i].detach() + 0.5).numpy()\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    # plt.show()\n",
        "    plt.axis('off')\n",
        "    plt.savefig(fname =f\"{BASE_DIR}/imgs_show/{i}_p5.png\", dpi = 300, transparent = True, bbox_inches = 'tight', pad_inches = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LcLCPlsM50B_",
        "outputId": "054ec9e2-9512-4637-e364-e3fd4094b697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}